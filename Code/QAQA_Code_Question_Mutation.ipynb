{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIKw_RVBQJxT"
      },
      "source": [
        "https://github.com/ShenQingchao/QAQA/tree/master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NX6cnOEHRkh"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/ShenQingchao/QAQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJJS3eFHTn7N",
        "outputId": "01379070-e1cf-413f-9c1a-540e25aa8e2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "#exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZIlLeGUTxIC"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wv-UJEheK3G6"
      },
      "outputs": [],
      "source": [
        "#!apt-get install python3.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YR8Rs_lTnS6"
      },
      "outputs": [],
      "source": [
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrpqXJLyVbhX"
      },
      "outputs": [],
      "source": [
        "!pip install benepar==0.2.0\n",
        "!pip install pattern==3.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDlxHdTXLDNr"
      },
      "outputs": [],
      "source": [
        "#!pip install neuralcoref==4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSKZcIxTT9mE"
      },
      "outputs": [],
      "source": [
        "#from QAUtil.qa import QA, QAList\n",
        "\n",
        "def load_qa(path, end_id=1363, remove_redundancy_context=False):\n",
        "    #data = pd.read_csv(path, sep='\\t', header=None, names=['q_c', 'a'])\n",
        "    data = pd.read_csv(path, encoding='utf-8')\n",
        "\n",
        "    qa_list_obj = QAList()\n",
        "    before_context = \"\"\n",
        "    print(\"Total data \"+str(len(data)))\n",
        "    for i in range(len(data)):\n",
        "        if i >= end_id:  # the max length of the dev-set is squad2_dev(11873)\n",
        "            break\n",
        "\n",
        "        uid = data['uid'][i]\n",
        "        question = data['question'][i]\n",
        "        answer = data['answer'][i]\n",
        "        title = data['so_question_title'][i]\n",
        "        context = 'Question: '+title + '\\n' +data['so_question_body'][i]+ '\\nAnswer: ' + data['so_answer'][i]\n",
        "\n",
        "        # question_context = data['q_c'][i]\n",
        "        # question = question_context.split(\"\\\\n\")[0]\n",
        "        # context_title = question_context.split(\"\\\\n\")[1]\n",
        "        # # print(i, question_context, context_title)\n",
        "        # title, context = extract_title_from_context(context_title)\n",
        "        if remove_redundancy_context and before_context == context:\n",
        "            # print(\"redundant context...\")\n",
        "            continue\n",
        "        qa = QA(question, answer, context, title, uid)\n",
        "        qa_list_obj.append_(qa)\n",
        "        before_context = context\n",
        "    logger.debug(f\"qa number: {len(data)}\")\n",
        "    qa_list_obj.set_all_context_embedding()\n",
        "    return qa_list_obj\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsVyUiLhT6Oq"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import util\n",
        "from sentence_transformers import SentenceTransformer\n",
        "sbert_model = SentenceTransformer('bert-base-nli-stsb-mean-tokens')  # ../3rd_models/multi-qa-MiniLM-L6-cos-v1\n",
        "\n",
        "def is_same_answer(ans1, ans2, is_bool=False):\n",
        "    ans1 = ans1.strip().lower()\n",
        "    ans2 = ans2.strip().lower()\n",
        "\n",
        "    original_embedding = sbert_model.encode(ans1)\n",
        "    compare_embedding = sbert_model.encode(ans2)\n",
        "\n",
        "    similarity = util.cos_sim(original_embedding, compare_embedding).tolist()[0]\n",
        "\n",
        "    if similarity[0] >= 0.76:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "def calculate_sim_origin_sentence(origin, target_list, top_n):\n",
        "    '''\n",
        "    This method can calculate the similarity between origin and target.\n",
        "    :param origin:  a word or a sentence.\n",
        "    :param target_list:  a list containing words or sentences.\n",
        "    :param top_n:  the number of return list.\n",
        "    :param context_embedding: the embedding of target_list.\n",
        "    :return: 2-dim list  --- the top_n most similar target words/sentences for origin; e.g., [('dog', 0.9), ('cat', 0.85)]\n",
        "    '''\n",
        "    sim_dict = {}\n",
        "    # model = SentenceTransformer('../pretrained-models/multi-qa-MiniLM-L6-cos-v1')   # bert-base-nli-stsb-mean-tokens , multi-qa-MiniLM-L6-cos-v1, paraphrase-MiniLM-L6-v2\n",
        "    w_embedding = sbert_model.encode(origin)\n",
        "\n",
        "    context_embedding = sbert_model.encode(target_list)\n",
        "    sim = util.cos_sim(w_embedding, context_embedding).tolist()[0]\n",
        "    # dict: {sent: sim_value}: first, load sent and score to a dict; and then rank by score--> convert to list\n",
        "    for i, score in enumerate(sim):\n",
        "        sim_dict[target_list[i]] = score\n",
        "    res_context_score_list = sorted(sim_dict.items(), key=lambda x: x[1], reverse=True)  # dict to 2-dim list\n",
        "    if not top_n:\n",
        "        top_n = len(target_list)\n",
        "    return res_context_score_list[:top_n]\n",
        "\n",
        "\n",
        "def calculate_sim_origin_target(origin, target_obj, top_n):\n",
        "    sim_dict = {}\n",
        "    c_embedding = target_obj.get_all_context_embedding()\n",
        "    print(\"Embedding count \"+str(len(c_embedding)))\n",
        "    # contexts_embedding = target_obj.get_all_context_embedding()\n",
        "    # contexts = list(contexts_embedding[:, 0])\n",
        "    # c_embedding = list(contexts_embedding[:, 1])\n",
        "    # model = SentenceTransformer('../pretrained-models/multi-qa-MiniLM-L6-cos-v1')   # bert-base-nli-stsb-mean-tokens , multi-qa-MiniLM-L6-cos-v1, paraphrase-MiniLM-L6-v2\n",
        "    w_embedding = sbert_model.encode(origin)\n",
        "    # sim = util.dot_score(w_embedding, c_embedding).tolist()[0]\n",
        "    sim = util.cos_sim(w_embedding, c_embedding).tolist()[0]\n",
        "\n",
        "    # return dict, <id, sim_value> # first: load qa_id and score to a dict, and then rank by score\n",
        "    for i, score in enumerate(sim):\n",
        "        sim_dict[i] = score\n",
        "    res_context_score_list = sorted(sim_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "    # for item in res_context_score_list[:top_n]:  # only print the top_n related context\n",
        "    #     print(item[1], item[0])\n",
        "    if not top_n:\n",
        "        top_n = len(c_embedding)\n",
        "    return res_context_score_list[:top_n]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXCOH4edT1v4"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/QAQA-master/scripts') # update location\n",
        "sys.path.append('/benepar_en3/') # update location\n",
        "\n",
        "from utils.my_logger import logger\n",
        "from utils.preprocess import word_embedding\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class QA:\n",
        "    count = 0\n",
        "    def __init__(self, q, a, c, t, uid):\n",
        "        self.id = QA.count  # identify the line number of the qa\n",
        "        QA.count += 1\n",
        "        self.uid = uid\n",
        "        self.Q = q\n",
        "        self.A = a\n",
        "        # self.C = context_preprocess(c)\n",
        "        self.C = c\n",
        "        self.T = t\n",
        "        self.C_Embedding = None\n",
        "        self.PA = None\n",
        "        # self.Q2S = q2s\n",
        "\n",
        "\n",
        "class QAList:\n",
        "    def __init__(self):\n",
        "        self.qa_list = []\n",
        "\n",
        "    def append_(self, qa):\n",
        "        self.qa_list.append(qa)\n",
        "\n",
        "    def remove_qa_of_this_context(self, context):\n",
        "        for idx, qa in enumerate(self.qa_list):\n",
        "        #for qa in self.qa_list:\n",
        "            if context == qa.C:\n",
        "                #print(qa.id)\n",
        "                self.qa_list[idx].C = ''\n",
        "                self.qa_list[idx].C_Embedding = np.zeros(shape=(768,), dtype='float32')\n",
        "                logger.debug(f\"line {qa.id+1} in training-set has the same context with current context:{context} \")\n",
        "\n",
        "    def set_all_context_embedding(self):\n",
        "        contexts_all = []\n",
        "        for qa in self.qa_list:\n",
        "            contexts_all.append(qa.C)\n",
        "        #context_all_embedding = word_embedding(contexts_all)\n",
        "\n",
        "        context_all_embedding = sbert_model.encode(contexts_all)\n",
        "\n",
        "        for id in range(len(self.qa_list)):\n",
        "            self.qa_list[id].C_Embedding = context_all_embedding[id]\n",
        "\n",
        "    def get_all_context_embedding(self):\n",
        "        context_embedding_list = []\n",
        "        for qa in self.qa_list:\n",
        "            context_embedding_list.append(qa.C_Embedding)\n",
        "        #return np.array(context_embedding_list)  # return np.array()\n",
        "        print(\"Embedding count \"+str(len(context_embedding_list)))\n",
        "        return context_embedding_list  # return np.array()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwuFLQrd3nmr",
        "outputId": "85d3b28e-3c8f-4c1f-b51d-254682a30444"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['EQ', 'EQC', 'ETI']\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import os\n",
        "import copy\n",
        "import sys\n",
        "sys.path.append('QAQA-master/scripts') # udpate location\n",
        "sys.path.append('QAQA-master/benepar_en3/') # udpate location\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from configparser import ConfigParser\n",
        "from utils.my_logger import logger\n",
        "#from utils.read_data import load_qa\n",
        "#from utils.model_predict import run_predict\n",
        "\n",
        "from generate.template import *\n",
        "# from calc_sim.sent_sim import calculate_sim_origin_target, calculate_sim_origin_sentence\n",
        "from utils.preprocess import get_sentences_from_contexts, context_preprocess\n",
        "# from calc_sim.answer_sim import is_same_answer\n",
        "\n",
        "\n",
        "begin_time = time.time()\n",
        "# # logger.debug(f\"Start to run the script {__file__}\")\n",
        "# project_name = sys.argv[1].strip()\n",
        "# config_file = ''\n",
        "# if project_name == 'boolq':\n",
        "#     config_file = 'config_boolq.ini'\n",
        "# elif project_name == 'squad2':\n",
        "#     config_file = 'config-squad2.ini'\n",
        "# elif project_name == 'narrative':\n",
        "#     config_file = 'config-narrative.ini'\n",
        "# else:\n",
        "#     assert False, \"No such project\"\n",
        "\n",
        "config = ConfigParser()\n",
        "config.read('/QAQA-master/scripts/config/config-narrative.ini') # update location\n",
        "params = config['PARAMETERS']\n",
        "\n",
        "data_dir = '/content/'\n",
        "training_set_file = data_dir + 'so_nltk_spacy_data_similar_answers_qaqa_input.csv' #params['TRAINING_FILE_PATH']\n",
        "test_set_file = training_set_file #params['TEST_FILE_PATH']\n",
        "\n",
        "# qa_model_path = params['QA_MODEL_PATH']\n",
        "attack_mods = ['EQ','EQC','ETI'] #params['ATTACK_MOD'].strip().split(',')\n",
        "extra_sent_num2context = int(params['EXTRA_NUM2C'].strip())\n",
        "max_attack_num = int(params['MAX_ATTACK_NUM'].strip())\n",
        "combined_context_num = int(params['CONTEXT_NUM'].strip())\n",
        "origin_answer_flag = params['ORIGIN_ANSWER']\n",
        "print(attack_mods)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKGt5aRaAn8P"
      },
      "outputs": [],
      "source": [
        "\n",
        "# suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def write_to_file(df, uid, attack_type, new_question, new_context, new_answer, new_predict_res, is_bug):\n",
        "  global file_comprehensive_res\n",
        "\n",
        "  df_out_row = df[df['uid'] == uid]\n",
        "\n",
        "  df_out_row['attack_type'] = attack_type.strip()\n",
        "  df_out_row['new_question'] = new_question.strip()\n",
        "  df_out_row['new_context'] = new_context.strip()\n",
        "  df_out_row['new_answer'] = new_answer.strip()\n",
        "  # df_out_row['new_predict_res'] = new_predict_res.strip()\n",
        "  # df_out_row['is_bug'] = is_bug\n",
        "\n",
        "  df_out = pd.read_csv(file_comprehensive_res, encoding='utf-8')\n",
        "  df_out = df_out.append(df_out_row, ignore_index=True)\n",
        "\n",
        "  df_out.to_csv(file_comprehensive_res, index=False, encoding='utf-8')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-LwQHMkGUDt9"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "import copy\n",
        "import sys\n",
        "sys.path.append('/QAQA-master/scripts') # update location\n",
        "sys.path.append('/QAQA-master/benepar_en3/')  # update location\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from configparser import ConfigParser\n",
        "from utils.my_logger import logger\n",
        "#from utils.read_data import load_qa\n",
        "#from utils.model_predict import run_predict\n",
        "\n",
        "from generate.template import *\n",
        "# from calc_sim.sent_sim import calculate_sim_origin_target, calculate_sim_origin_sentence\n",
        "from utils.preprocess import get_sentences_from_contexts, context_preprocess\n",
        "# from calc_sim.answer_sim import is_same_answer\n",
        "\n",
        "\n",
        "begin_time = time.time()\n",
        "# # logger.debug(f\"Start to run the script {__file__}\")\n",
        "# project_name = sys.argv[1].strip()\n",
        "# config_file = ''\n",
        "# if project_name == 'boolq':\n",
        "#     config_file = 'config_boolq.ini'\n",
        "# elif project_name == 'squad2':\n",
        "#     config_file = 'config-squad2.ini'\n",
        "# elif project_name == 'narrative':\n",
        "#     config_file = 'config-narrative.ini'\n",
        "# else:\n",
        "#     assert False, \"No such project\"\n",
        "\n",
        "config = ConfigParser()\n",
        "config.read('/QAQA-master/scripts/config/config-narrative.ini')  # update location\n",
        "params = config['PARAMETERS']\n",
        "\n",
        "data_dir = '/content/'\n",
        "training_set_file = data_dir + 'so_nltk_spacy_data_similar_answers_qaqa_input.csv' #params['TRAINING_FILE_PATH']\n",
        "test_set_file = training_set_file #params['TEST_FILE_PATH']\n",
        "\n",
        "# qa_model_path = params['QA_MODEL_PATH']\n",
        "attack_mods = params['ATTACK_MOD'].strip().split(',')\n",
        "attack_mods = ['EQ','EQC','ETI']\n",
        "extra_sent_num2context = int(params['EXTRA_NUM2C'].strip())\n",
        "max_attack_num = int(params['MAX_ATTACK_NUM'].strip())\n",
        "combined_context_num = int(params['CONTEXT_NUM'].strip())\n",
        "origin_answer_flag = params['ORIGIN_ANSWER']\n",
        "# ------------------------------------------------------------------------------------------------------------------\n",
        "project_name = test_set_file.split(\"data_\")[-1].split('_')[0]\n",
        "logger.debug(f\"project name: {project_name}\")\n",
        "if project_name != \"boolq\" and \"TI\" in attack_mods:\n",
        "    attack_mods.remove(\"TI\")\n",
        "is_boolq = False\n",
        "if project_name == 'boolq':\n",
        "    is_boolq = True\n",
        "\n",
        "res_dir = data_dir # f'../results/{project_name}/res-dev'\n",
        "if not os.path.exists(res_dir):\n",
        "    os.makedirs(res_dir)\n",
        "file_comprehensive_res = data_dir + 'so_nltk_spacy_data_similar_answers_qaqa_applied_Questions_Only.csv' # os.path.join(res_dir, \"so_nltk_spacy_data_similar_answers_qaqa_test_cases_all.csv\")\n",
        "# file_comprehensive_res_bug = os.path.join(res_dir, \"so_nltk_spacy_data_similar_answers_qaqa_violation_all.csv\")\n",
        "\n",
        "# ----------------------------load training set and development set ------------------------------------------------\n",
        "\n",
        "data = pd.read_csv(test_set_file, encoding='utf-8')\n",
        "df_out = pd.read_csv(file_comprehensive_res, encoding='utf-8')\n",
        "\n",
        "qa_list_obj_test = load_qa(test_set_file, end_id=2000)\n",
        "logger.debug(\"origin question number: \" + str(len(qa_list_obj_test.qa_list)))\n",
        "qa_list_obj_training = load_qa(training_set_file, end_id=2000, remove_redundancy_context=True)\n",
        "\n",
        "# with open(f\"../datasets/compress/{project_name}.comp.tsv\", \"r\", encoding=\"utf-8\") as f:\n",
        "compress_question_list = data['question']\n",
        "\n",
        "for obj in qa_list_obj_test.qa_list:\n",
        "    is_bug = False\n",
        "    new_question = ''\n",
        "    new_context = ''\n",
        "    new_answer = ''\n",
        "    new_predict_res = ''\n",
        "\n",
        "    existing_id = df_out[df_out['uid'] == obj.uid]['uid'].tolist()\n",
        "    if len(existing_id) > 0:\n",
        "      continue\n",
        "\n",
        "\n",
        "    this_attack = random.choice(attack_mods)\n",
        "    logger.info(f\"The qa id[test-set] is: {obj.id}\")\n",
        "    if origin_answer_flag == 'SUT':\n",
        "        ori_ans =  obj.A # AUTHOR Change# run_predict(obj.Q + '\\n ' + '('+obj.T+') ' + obj.C)[0]\n",
        "    elif origin_answer_flag == 'GT':\n",
        "        ori_ans = obj.A\n",
        "    else:\n",
        "        raise Exception(print(\"wrong key of origin_answer_flag!\"))\n",
        "    # ----------calculate the similarity between question and each context------------------------------------------\n",
        "    # -------ignore the qa[in train-set] that have same context with current context.-------------------------------\n",
        "    qa_list_obj_training_no_this = copy.deepcopy(qa_list_obj_training)\n",
        "    qa_list_obj_training_no_this.remove_qa_of_this_context(obj.C)\n",
        "    # calculate sim between 'question' in dev-set and 'context' in train-set!   return [(id,sim_value)]\n",
        "    # compress question into simple question.\n",
        "    temp_line_list = compress_question_list[obj.id].split(\"\\t\")\n",
        "    if not obj.Q.strip().startswith(temp_line_list[0].strip()):\n",
        "        logger.warn(\"check is same: \" + obj.Q + \", \" + temp_line_list[0])\n",
        "    compress_qu = temp_line_list[-1].strip() + \"?\"\n",
        "\n",
        "    top_n_sim_contexts_list = calculate_sim_origin_target(compress_qu, qa_list_obj_training_no_this, combined_context_num)\n",
        "    # print(\"top_n_sim_contexts_list:\", top_n_sim_contexts_list)\n",
        "    # ------------------------ split top-n similarity contexts into a sentences list. ------------------------------\n",
        "    extra_sentences_list = []\n",
        "    sentence_qa_id_dict = {}\n",
        "    for count in range(combined_context_num):\n",
        "        if count >= len(top_n_sim_contexts_list):\n",
        "          break\n",
        "        context_qa_id = top_n_sim_contexts_list[count][0]\n",
        "        this_qa = qa_list_obj_training_no_this.qa_list[context_qa_id]\n",
        "        this_sentences_list = get_sentences_from_contexts([this_qa.C])  # eliminate coreference in this process.\n",
        "        extra_sentences_list.extend(this_sentences_list)\n",
        "        for s in this_sentences_list:\n",
        "            sentence_qa_id_dict[s] = context_qa_id\n",
        "\n",
        "    # ------------calculate the similarity between question and each sentence from context--------------------------\n",
        "    top_N_sim_sentences_list = calculate_sim_origin_sentence(compress_qu, extra_sentences_list,\n",
        "                                                              top_n=max_attack_num+extra_sent_num2context-1)\n",
        "    # top_N_sim_sentences_list = list(np.array(top_N_sim_sentences_list_)[:, 0])\n",
        "    logger.debug(\"..................................................................\")\n",
        "    logger.debug(f\"origin question is: {obj.Q}\")\n",
        "    logger.debug(f\"compress question is: {compress_qu}\")\n",
        "    logger.debug(\"top_N_sim_sentences_list\" + str(top_N_sim_sentences_list))  # [(sentence, sim)]\n",
        "\n",
        "    for attack_times in range(max_attack_num):\n",
        "        # --------------------------------generate a new input(question, context) and answer------------------------\n",
        "        selected_sent = top_N_sim_sentences_list[attack_times][0]\n",
        "        selected_sent_processed = context_preprocess(selected_sent)  # remove bracket.\n",
        "        selected_sent_next = top_N_sim_sentences_list[attack_times+1][0]\n",
        "        sim_question_sent = top_N_sim_sentences_list[attack_times][1]\n",
        "\n",
        "        # for fear the selected question is too short(e.g., only contain a single word)\n",
        "        if len(selected_sent_processed) < 10:\n",
        "            selected_sent_processed = selected_sent_next\n",
        "        # --------------------combine multi sent to one that will be insert into origin contexts--------------------\n",
        "        selected_sent_combine = ''\n",
        "        for i in range(extra_sent_num2context):\n",
        "            if attack_times + i < len(top_N_sim_sentences_list):  # for fear index out of boundary\n",
        "                selected_sent_combine += (top_N_sim_sentences_list[attack_times + i][0] + ' ')\n",
        "            else:\n",
        "                selected_sent_combine = selected_sent_processed\n",
        "                logger.warn(\"[Warning!] [index out of scope] the hyper-parameter 'CONTEXT_NUM' is too small! \")\n",
        "\n",
        "        if 'EC' == this_attack:\n",
        "            new_context = add_extra2context(obj.C, selected_sent_combine)\n",
        "            new_question = obj.Q\n",
        "            # new_predict_res = run_predict(new_question + '\\n '+new_context)[0]  # ('+obj.T+')\n",
        "            # if not is_same_answer(new_predict_res, ori_ans, is_bool=is_boolq):\n",
        "            #     logger.debug('.....................A Successful EC Attack...................................\\n')\n",
        "            #     logger.debug(f\"Question: {new_question}\")\n",
        "            #     logger.debug(f\"Origin context: {obj.C}\")\n",
        "            #     logger.debug(f\"New context: {new_context}\")\n",
        "            #     logger.debug(f\"Ground truth:{obj.A}, New answer:{new_predict_res}\")\n",
        "            #     logger.debug('...................................................................................\\n')\n",
        "            #     is_bug = True\n",
        "                # str_output_bug = f\"{obj.id}\\t{new_question} \\\\n {new_context}\\t{ori_ans}->{new_predict_res}\\tEC\\n\"\n",
        "                # with open(file_comprehensive_res_bug, 'a', encoding='utf-8') as f:\n",
        "                #     f.write(str_output_bug)\n",
        "            # str_output = f\"{new_question} \\\\n {new_context}\\t{ori_ans}\\t{new_predict_res}\\n\"\n",
        "            # with open(file_comprehensive_res, 'a', encoding='utf-8') as f:\n",
        "            #     f.write(str_output)\n",
        "            write_to_file(data, obj.uid, this_attack, new_question, new_context, new_answer, new_predict_res, is_bug)\n",
        "\n",
        "        if 'EQ' == this_attack:\n",
        "            new_question = obj.Q\n",
        "            if project_name == 'boolq' and random.randint(0, 1) == 1:\n",
        "                new_question = negative_question(new_question)\n",
        "            new_question = add_extra2question(new_question, selected_sent_processed)\n",
        "            # new_predict_res = run_predict(new_question + '\\n '+obj.C)[0]  # ('+obj.T+')\n",
        "            # if not is_same_answer(new_predict_res, ori_ans, is_bool=is_boolq):\n",
        "            #     logger.debug('.....................A Successful EQ Attack...................................\\n')\n",
        "            #     logger.debug(f\"Origin question: {obj.Q}\")\n",
        "            #     logger.debug(f\"New question: {new_question}\")\n",
        "            #     logger.debug(f\"Context: {obj.C}\")\n",
        "            #     logger.debug(f\"Ground truth:{ori_ans}, Predicting answer:{new_predict_res}\")\n",
        "            #     logger.debug('...................................................................................\\n')\n",
        "                # str_output_bug = f\"{obj.id}\\t{new_question} \\\\n {obj.C}\\t{ori_ans}->{new_predict_res}\\tEQ\\n\"\n",
        "                # with open(file_comprehensive_res_bug, 'a', encoding='utf-8') as f:\n",
        "                #     f.write(str_output_bug)\n",
        "            # str_output = f\"{new_question} \\\\n {obj.C}\\t{ori_ans}\\t{new_predict_res}\\n\"\n",
        "            # with open(file_comprehensive_res, 'a', encoding='utf-8') as f:\n",
        "            #     f.write(str_output)\n",
        "            write_to_file(data, obj.uid, this_attack, new_question, new_context, new_answer, new_predict_res, is_bug)\n",
        "\n",
        "\n",
        "        if 'EQC' == this_attack:\n",
        "            new_question = obj.Q\n",
        "            if project_name == 'boolq' and random.randint(0, 1) == 1:   # [WARNING] add negative attack!!!\n",
        "                new_question = negative_question(new_question)\n",
        "            new_question = add_extra2question(new_question, selected_sent_processed)\n",
        "            #AUTHOR DISABLED IT: new_context = add_extra2context(obj.C, selected_sent_combine if ori_ans == 'no' else selected_sent_next)\n",
        "            # new_predict_res = run_predict(new_question + '\\n '+new_context)[0]   # ('+obj.T+')\n",
        "            # if not is_same_answer(new_predict_res, ori_ans, is_bool=is_boolq):\n",
        "            #     logger.debug('.....................A Successful  EQC Attack.................................\\n')\n",
        "            #     logger.debug(f\"New question: {new_question}\")\n",
        "            #     logger.debug(f\"New context: {new_context}\")\n",
        "            #     logger.debug(f\"Ground truth:{ori_ans}, Predicting answer:{new_predict_res}\")\n",
        "            #     logger.debug('...................................................................................\\n')\n",
        "                # str_output_bug = f\"{obj.id}\\t{new_question} \\\\n {new_context}\\t{ori_ans}->{new_predict_res}\\tEQC\\n\"\n",
        "                # with open(file_comprehensive_res_bug, 'a', encoding='utf-8') as f:\n",
        "                #     f.write(str_output_bug)\n",
        "            # str_output = f\"{new_question} \\\\n {new_context}\\t{ori_ans}\\t{new_predict_res}\\n\"\n",
        "            # with open(file_comprehensive_res, 'a', encoding='utf-8') as f:\n",
        "            #     f.write(str_output)\n",
        "            write_to_file(data, obj.uid, this_attack, new_question, new_context, new_answer, new_predict_res, is_bug)\n",
        "\n",
        "        if 'ETI' == this_attack:\n",
        "            selected_qa_id = sentence_qa_id_dict[selected_sent]\n",
        "            selected_qa = qa_list_obj_training_no_this.qa_list[selected_qa_id]\n",
        "            if project_name == \"boolq\":\n",
        "                new_question, new_context = add_input_as_redundancy(obj, selected_qa)\n",
        "            else:\n",
        "                new_question, new_context = add_wh_question_as_redundancy(obj, selected_qa)\n",
        "            # new_predict_res = run_predict(new_question + '\\n '+new_context)[0]  # ('+obj.T+' && '+selected_qa.T+')\n",
        "            # if not is_same_answer(new_predict_res, ori_ans, is_bool=is_boolq):\n",
        "            #     logger.debug('....................A Successful ETI Attack........................\\n')\n",
        "            #     logger.debug(f\"Origin question: {obj.Q}\")\n",
        "            #     logger.debug(f\"Selected question: {selected_qa.Q}\")\n",
        "            #     logger.debug(f\"New Question: {new_question}\")\n",
        "            #     logger.debug(f\"Origin context: {obj.C}\")\n",
        "            #     logger.debug(f\"Selected context: {selected_qa.C}\")\n",
        "            #     logger.debug(f\"New context: {new_context}\")\n",
        "            #     logger.debug(f\"Ground truth:{ori_ans}, Predicting answer:{new_predict_res}\")\n",
        "            #     logger.debug('...................................................................................\\n')\n",
        "                # str_output_bug = f\"{obj.id}\\t{new_question} \\\\n {new_context}\\t{ori_ans}->{new_predict_res}\\tETI\\n\"\n",
        "                # with open(file_comprehensive_res_bug, 'a', encoding='utf-8') as f:\n",
        "                #     f.write(str_output_bug)\n",
        "            # str_output = f\"{new_question} \\\\n {new_context}\\t{ori_ans}\\t{new_predict_res}\\n\"\n",
        "            # with open(file_comprehensive_res, 'a', encoding='utf-8') as f:\n",
        "            #     f.write(str_output)\n",
        "            write_to_file(data, obj.uid, this_attack, new_question, '', new_answer, new_predict_res, is_bug) # AUTHOR: DO NOT WRITE CONTEXT\n",
        "\n",
        "        if 'TI' == this_attack:\n",
        "            selected_qa_id = sentence_qa_id_dict[selected_sent]\n",
        "            selected_qa = qa_list_obj_training_no_this.qa_list[selected_qa_id]\n",
        "            ori_ans2 = selected_qa.A if origin_answer_flag == 'GT' \\\n",
        "                else run_predict(selected_qa.Q + '\\n (' + selected_qa.T + ')' + selected_qa.C)[0]\n",
        "\n",
        "            new_question, new_context, new_answer = combine2input(obj, selected_qa, ori_ans, ori_ans2)\n",
        "            # new_predict_res = run_predict(new_question + '\\n '+new_context)[0]  # ('+obj.T+' && '+selected_qa.T+')\n",
        "            # if not is_same_answer(new_predict_res, new_answer, is_bool=is_boolq):\n",
        "            #     logger.debug('.....................A Successful TI Attack............................\\n')\n",
        "            #     logger.debug(f\"Origin question: {obj.Q}\")\n",
        "            #     logger.debug(f\"Selected question: {selected_qa.Q}\")\n",
        "            #     logger.debug(f\"New Question: {new_question}\")\n",
        "            #     logger.debug(f\"Origin context: {obj.C}\")\n",
        "            #     logger.debug(f\"Selected context: {selected_qa.C}\")\n",
        "            #     logger.debug(f\"New context: {new_context}\")\n",
        "            #     logger.debug(f\"Ground truth:{ori_ans}+{ori_ans2}={new_answer}, Predicting answer:{new_predict_res}\")\n",
        "            #     logger.debug('...................................................................................\\n')\n",
        "                # str_output_bug = f\"{obj.id}\\t{new_question} \\\\n {new_context}\\t{new_answer}->{new_predict_res}\\tTI\\n\"\n",
        "                # with open(file_comprehensive_res_bug, 'a', encoding='utf-8') as f:\n",
        "                #     f.write(str_output_bug)\n",
        "            # str_output = f\"{new_question} \\\\n {new_context}\\t{new_answer}\\t{new_predict_res}\\n\"\n",
        "            # with open(file_comprehensive_res, 'a', encoding='utf-8') as f:\n",
        "            #     f.write(str_output)\n",
        "\n",
        "            write_to_file(data, obj.uid, this_attack, new_question, new_context, new_answer, new_predict_res, is_bug)\n",
        "\n",
        "    #     break\n",
        "    # break\n",
        "\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "logger.debug(f\"Finish question_gen for question_{obj.id},during time is {round(end_time - begin_time, 2)}s\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}